# Qdrant Configuration
# Mode: "cloud" | "docker" | "embedded" (default: "docker")
QDRANT_MODE=docker

# Qdrant connection URL (default: "http://localhost:6333")
QDRANT_URL=http://localhost:6333

# Qdrant API key (required for cloud mode, optional for others)
QDRANT_API_KEY=

# Qdrant collection name (default: "law_docs_v1")
QDRANT_COLLECTION=law_docs_v1

# Qdrant collection alias for operations (default: "law_docs_current")
QDRANT_COLLECTION_ALIAS=law_docs_current

# Logging Configuration
# Log level: DEBUG, INFO, WARNING, ERROR, CRITICAL (default: "INFO")
LOG_LEVEL=INFO

# Enable Qdrant HTTP client logging: "0" or "1" (default: "0")
LOG_QDRANT_HTTP=0

# OpenAI / LLM
OPENAI_API_KEY=
LLM_PROVIDER=openai
OPENAI_COMPLETION_MODEL=gpt-5-mini
OPENAI_COMPLETION_MODEL_FALLBACK=gpt-5-nano

# Intelligent Model Routing (QA vs DocGen)
# Q&A model for general RAG queries (fast, efficient)
QA_MODEL=gpt-4o-mini
# Document generation model for drafting legal documents (higher quality)
DOCGEN_MODEL=gpt-5
# Max tokens for Q&A responses
QA_MAX_TOKENS=900
# Max tokens for document generation (higher for complete drafts)
DOCGEN_MAX_TOKENS=5200
# Top-K retrieval for document generation (wider search for templates)
DOCGEN_TOP_K=12
# Context window for document generation (more context for better templates)
DOCGEN_CONTEXT_CHARS=16000

# Web Search (optional)
# If TAVILY_API_KEY is set, web fallback can be enabled.
TAVILY_API_KEY=
WEB_SEARCH_ENABLED=true

# Chat Memory Configuration
# Database URL for persistent chat history
# SQLite (default): sqlite+aiosqlite:///./brag_ai.sqlite
# PostgreSQL: postgresql+asyncpg://user:password@host:port/database
DATABASE_URL=sqlite+aiosqlite:///./brag_ai.sqlite

# Redis URL for ephemeral conversation buffer (optional)
# If not set, falls back to in-memory buffer
# Example: redis://localhost:6379/0
REDIS_URL=